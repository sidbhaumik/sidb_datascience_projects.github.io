{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiTCoCvQwzW6WsN0SRCC5+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidbhaumik/sidb_datascience_projects.github.io/blob/main/deeplearning_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We will implement three different Neural Network Architecture:\n",
        "## - Feedforward Neural Networks (FNNs),\n",
        "## - Convolutional Neural Networks (CNNs),\n",
        "## - Recurrent Neural Networks (RNNs)."
      ],
      "metadata": {
        "id": "2kuk5Lo-fekJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Set up the environment\n",
        "Before starting, ensure that we have TensorFlow installed. We can install it using the following command:"
      ],
      "metadata": {
        "id": "YGOKhVrEfz6L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FANgPU_fI4Y",
        "outputId": "36c5d1cf-7109-4861-846f-e16493f01da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries to build and train the neural networks:"
      ],
      "metadata": {
        "id": "GGpud976gBaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "dVSTzWspf46E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Implement a feedforward neural network (FNN)"
      ],
      "metadata": {
        "id": "P53QKvZfgQUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We built a simple FNN to classify the **Iris flower** dataset."
      ],
      "metadata": {
        "id": "Z4MQnwQyhDP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2a: Load and prepare the data\n",
        "We started by loading the Iris dataset, one-hot encoding the target labels, and splitting the data into training and testing sets."
      ],
      "metadata": {
        "id": "3muFl7ONhMT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "# Load IRIS Flower dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "pp_kTbVpgFnS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**X** contains measurements of flowers (sepal length, petal width, etc.)\n",
        "\n",
        "**y** contains class labels: 0 = Setosa, 1 = Versicolor, 2 = Virginica\n",
        "\n",
        "**.reshape(-1, 1)** converts a 1D array into a 2D column vector, which is needed for encoding."
      ],
      "metadata": {
        "id": "P2QrNjkkjx4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder()\n",
        "y = encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "1oE0xcPHh3Om"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms **y** from [0], [1], [2] → into one-hot format:\n",
        "\n",
        "0 → [1, 0, 0]\n",
        "\n",
        "1 → [0, 1, 0]\n",
        "\n",
        "2 → [0, 0, 1]\n",
        "\n",
        "**fit_transform()** both learns the encoding and applies it."
      ],
      "metadata": {
        "id": "UitLYnGPnKs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the sparse matrix to a dense NumPy array\n",
        "y = y.toarray()"
      ],
      "metadata": {
        "id": "993aIUUXngRw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result from OneHotEncoder is a sparse matrix (efficient format for storage).\n",
        "\n",
        "**.toarray()** converts it into a regular (dense) NumPy array so we can use it easily with libraries like TensorFlow/Keras."
      ],
      "metadata": {
        "id": "ti391Iwzrm8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZpY0D0J2iID1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splits the dataset into:\n",
        "\n",
        "80% training data\n",
        "\n",
        "20% testing data\n",
        "\n",
        "**random_state=42** ensures reproducibility (this gives same split every time)."
      ],
      "metadata": {
        "id": "oMp7I2krr28a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2b: Build the FNN\n",
        "A simple FNN architecture was created with two hidden layers. ReLU activation functions were applied to introduce non-linearity."
      ],
      "metadata": {
        "id": "Q53G43zti3EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the FNN model\n",
        "model_fnn = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')  # 3 output classes\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzoTGTDFiuSv",
        "outputId": "d144151e-e584-425b-8b05-bdb43575807d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What this does?\n",
        "- models.Sequential :\n",
        "  Creates a Sequential model — a linear stack of layers (input → hidden layers → output).\n",
        "- layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)) :\n",
        "\n",
        "   Adds the first hidden layer:\n",
        "\n",
        "  - Dense(64) → a fully connected layer with 64 neurons.\n",
        "\n",
        "  - activation='relu' → uses the ReLU activation function, introducing non-linearity.\n",
        "\n",
        "  - input_shape=(X_train.shape[1],) → sets the input size to match the number of features (columns) in your training data (X_train).\n",
        "\n",
        "- layers.Dense(32, activation='relu') : Adds a second hidden layer with 32 neurons and ReLU activation.\n",
        "\n",
        "- layers.Dense(3, activation='softmax') :\n",
        "\n",
        "  Adds the output layer:\n",
        "\n",
        "  - Dense(3) → 3 neurons for 3 output classes (multiclass classification).\n",
        "\n",
        "  - activation='softmax' → converts output scores into probabilities (values between 0 and 1 that sum to 1)."
      ],
      "metadata": {
        "id": "Ud_2jzmnkMs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2c: Compile and train the model\n",
        "The model was compiled with the Adam optimizer and categorical crossentropy loss, then trained for 20 epochs."
      ],
      "metadata": {
        "id": "8VtGYXzWmf69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_fnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3h6AX_ITjbtl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What this does?\n",
        "\n",
        "- optimizer='adam'\n",
        "\n",
        "  - Uses the Adam optimizer, a popular algorithm that adjusts learning rates automatically during training.\n",
        "\n",
        "  - It’s fast and works well in most deep learning problems.\n",
        "\n",
        "- loss='categorical_crossentropy'\n",
        "\n",
        "  - This is the loss function used for multiclass classification problems when your labels are one-hot encoded (i.e., [1,0,0], [0,1,0], etc.).\n",
        "\n",
        "   It measures how far off the predicted probabilities are from the actual class.\n",
        "\n",
        "- metrics=['accuracy']\n",
        "\n",
        "  - Tracks accuracy as the evaluation metric during training and validation."
      ],
      "metadata": {
        "id": "sH_KHBhXrbyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "model_fnn.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwVHJ-Tvmt-I",
        "outputId": "ef547b1d-4751-4589-e75d-93d62573d2de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.3748 - loss: 1.4120 - val_accuracy: 0.4000 - val_loss: 1.1287\n",
            "Epoch 2/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5854 - loss: 1.1563 - val_accuracy: 0.7000 - val_loss: 0.9759\n",
            "Epoch 3/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6702 - loss: 0.9833 - val_accuracy: 0.6333 - val_loss: 0.9676\n",
            "Epoch 4/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6846 - loss: 0.9424 - val_accuracy: 0.4000 - val_loss: 0.9608\n",
            "Epoch 5/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5656 - loss: 0.9204 - val_accuracy: 0.6333 - val_loss: 0.9052\n",
            "Epoch 6/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6979 - loss: 0.8866 - val_accuracy: 0.8333 - val_loss: 0.8392\n",
            "Epoch 7/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8025 - loss: 0.8401 - val_accuracy: 0.7000 - val_loss: 0.8011\n",
            "Epoch 8/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6415 - loss: 0.8143 - val_accuracy: 0.7000 - val_loss: 0.7729\n",
            "Epoch 9/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6435 - loss: 0.7881 - val_accuracy: 0.7000 - val_loss: 0.7446\n",
            "Epoch 10/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6279 - loss: 0.7709 - val_accuracy: 0.7333 - val_loss: 0.7197\n",
            "Epoch 11/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6815 - loss: 0.7304 - val_accuracy: 0.8000 - val_loss: 0.6969\n",
            "Epoch 12/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8652 - loss: 0.6901 - val_accuracy: 0.8333 - val_loss: 0.6727\n",
            "Epoch 13/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9135 - loss: 0.6750 - val_accuracy: 0.9667 - val_loss: 0.6534\n",
            "Epoch 14/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9496 - loss: 0.6472 - val_accuracy: 0.9000 - val_loss: 0.6258\n",
            "Epoch 15/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9185 - loss: 0.6155 - val_accuracy: 0.8000 - val_loss: 0.5978\n",
            "Epoch 16/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8675 - loss: 0.5949 - val_accuracy: 0.8000 - val_loss: 0.5751\n",
            "Epoch 17/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8910 - loss: 0.5954 - val_accuracy: 0.8667 - val_loss: 0.5555\n",
            "Epoch 18/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9190 - loss: 0.5628 - val_accuracy: 0.9333 - val_loss: 0.5371\n",
            "Epoch 19/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9308 - loss: 0.5323 - val_accuracy: 0.9667 - val_loss: 0.5185\n",
            "Epoch 20/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9525 - loss: 0.5066 - val_accuracy: 0.9333 - val_loss: 0.4980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b36bf914550>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        "- X_train, y_train\n",
        "\n",
        "  - Your training data: features and labels.\n",
        "\n",
        "- epochs=20\n",
        "\n",
        "  - The model will go through the entire training dataset 20 times.\n",
        "\n",
        "    More epochs = longer training, but possibly better accuracy (up to a point).\n",
        "\n",
        "- batch_size=32\n",
        "\n",
        "  - The training data is split into mini-batches of 32 samples at a time before updating the model.\n",
        "\n",
        "     Helps with efficiency and model convergence.\n",
        "\n",
        "- validation_data=(X_test, y_test)\n",
        "\n",
        "  - After each epoch, the model is evaluated on test (validation) data.\n",
        "\n",
        "     Helps track performance on unseen data to detect overfitting."
      ],
      "metadata": {
        "id": "kuTolQe7vA59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, in simple words, we are telling the model that Use the Adam optimizer and measure accuracy. Train for 20 epochs, 32 samples at a time. After each epoch, check how well its doing on the test set using accuracy."
      ],
      "metadata": {
        "id": "4w4Nlpvjv8Ce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2d: Model Evaluation"
      ],
      "metadata": {
        "id": "cl0bNVEGyAHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_fnn.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqM8vQ2ltdu4",
        "outputId": "64380fca-10b9-4337-f029-9dc6dd564a78"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9333 - loss: 0.4980\n",
            "Test Accuracy: 0.9333333373069763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        " model_fnn.evaluate(X_test, y_test):\n",
        "This command evaluates the trained model on the test dataset.\n",
        "\n",
        "It runs the model on X_test (features) and compares the predictions with y_test (true labels).\n",
        "\n",
        "It returns two values:\n",
        "\n",
        "1. loss: How far the predictions are from the true values (measured using the loss function defined earlier: categorical_crossentropy)\n",
        "\n",
        "2. accuracy: The proportion of correct predictions out of total samples (since we specified metrics=['accuracy'] earlier)"
      ],
      "metadata": {
        "id": "hXRW7aWXXnEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion:\n",
        "The model correctly predicted 93.3% of the test samples. This shows FNNs are well suited for simple classification tasks."
      ],
      "metadata": {
        "id": "zj6dL7qQYK9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Implementing a convolutional neural network (CNN)"
      ],
      "metadata": {
        "id": "osyL9CtKYcDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a CNN to classify images from the **CIFAR-10 dataset**."
      ],
      "metadata": {
        "id": "-DND5YQOYuuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3a: Load and preprocess the data\n",
        "Load the CIFAR-10 data."
      ],
      "metadata": {
        "id": "jeQnUnguMlvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAyKh5RLYQKi",
        "outputId": "3e089198-9ef5-4810-c9f0-5a1166ba1426"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.keras.datasets.cifar10** is a built-in dataset in TensorFlow.\n",
        "\n",
        "It loads 60,000 color images, each of size 32×32 pixels, across 10 classes.\n",
        "\n",
        "Splits the data into:\n",
        "\n",
        "- train_images (50,000 images for training)\n",
        "\n",
        "- test_images (10,000 images for testing)\n",
        "\n",
        "\n",
        "Each image has a label like:\n",
        "\n",
        "0 = airplane\n",
        "\n",
        "1 = automobile\n",
        "\n",
        "2 = bird\n",
        "\n",
        "till 9"
      ],
      "metadata": {
        "id": "Pwp78NaLuLLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the images to have pixel values between zero and one to facilitate efficient training."
      ],
      "metadata": {
        "id": "-AkoqeJlvIf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "fFf-Mduxuuf6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pixel values in images range from 0 to 255 (as integers).\n",
        "\n",
        "Dividing by 255.0 scales all values to range between 0 and 1, which:\n",
        "\n",
        " - Improves training performance and model stability\n",
        "\n",
        " - Helps the neural network converge faster."
      ],
      "metadata": {
        "id": "QcaEHSzyvUJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3b: Build the CNN\n",
        "The CNN consisted of two convolutional layers followed by max-pooling layers, which reduce the spatial dimensions of the data."
      ],
      "metadata": {
        "id": "lir9VCXVU7EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model_cnn = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # 10 output classes\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlP26HvjNTqM",
        "outputId": "ea31e95c-b0b6-42b5-8acb-122f54c1d2d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        " - model_cnn = models.Sequential :\n",
        "  This creates a Sequential model, meaning layers are stacked one after another in a straight line.\n",
        " - layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)) :\n",
        "\n",
        "   - Conv2D(32, (3, 3)): Applies 32 filters, each of size 3×3.\n",
        "\n",
        "   - activation='relu': Adds non-linearity to learn complex patterns.\n",
        "\n",
        "   - input_shape=(32, 32, 3): Input images are 32x32 pixels with 3 channels (RGB).\n",
        "\n",
        " Purpose: Detect basic features like edges or color patterns.\n",
        "\n",
        "- layers.MaxPooling2D((2, 2)) :\n",
        "    - First pooling layer. Downsamples the feature maps using max pooling with a 2×2 window.\n",
        "    - This reduces spatial size by half (from 32x32 to 16x16), decreasing computation and helping prevent overfitting.\n",
        "- layers.Conv2D(64, (3, 3), activation='relu') :\n",
        "  - Second Convolutional Layer. Adds 64 filters of size 3×3.\n",
        "\n",
        "  - Detects more complex patterns in the image (e.g., textures, shapes).\n",
        "- layers.MaxPooling2D((2, 2)) :\n",
        "  - Second Pooling layer. Downsamples again to reduce the feature map size further (now likely 8×8 if padding is default).\n",
        "- layers.Flatten() :\n",
        "  - Converts the 2D feature maps into a 1D vector so it can be passed into dense (fully connected) layers.\n",
        "\n",
        " For example, a 64×8×8 tensor becomes a 4096-element vector.\n",
        "- layers.Dense(64, activation='relu') :\n",
        "    - Adds a fully connected layer with 64 neurons and ReLU activation.\n",
        "\n",
        "  Learns complex combinations of features for classification.\n",
        "\n",
        "- layers.Dense(10, activation='softmax') :\n",
        "  - Final layer with 10 neurons, one for each class in CIFAR-10.\n",
        "\n",
        "  - Softmax converts raw scores into probabilities that sum to 1."
      ],
      "metadata": {
        "id": "RKRsRZZpPZ8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3c: Compile and train the model\n",
        "The model was compiled with sparse categorical crossentropy (suitable for integer labels) and trained for ten epochs."
      ],
      "metadata": {
        "id": "TNUxvJEWVIth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YzglsKpOPJSW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        "- optimizer='adam'\n",
        "\n",
        "  Uses the Adam optimizer, a popular and efficient choice for training neural networks.\n",
        "\n",
        "  It automatically adjusts learning rates during training for better convergence.\n",
        "\n",
        "- loss='sparse_categorical_crossentropy'\n",
        "\n",
        " This is used for multiclass classification when your target labels are integers (like 0, 1, 2, ..., 9).\n",
        "\n",
        "  Unlike categorical_crossentropy, this does not require one-hot encoding of the labels.\n",
        "\n",
        "  Example:\n",
        "\n",
        "    2 → means \"class 2\" (instead of [0, 0, 1, 0, ..., 0])\n",
        "\n",
        "- metrics=['accuracy']\n",
        "\n",
        "  Tracks accuracy during training and validation to evaluate how well the model is performing."
      ],
      "metadata": {
        "id": "Wy6lMvxLVeDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "model_cnn.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBHVW2ImWV-s",
        "outputId": "81ee738f-440b-4f58-8eb0-e339976c8ceb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 44ms/step - accuracy: 0.3462 - loss: 1.7839 - val_accuracy: 0.5434 - val_loss: 1.2950\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.5650 - loss: 1.2366 - val_accuracy: 0.6105 - val_loss: 1.1107\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 47ms/step - accuracy: 0.6322 - loss: 1.0613 - val_accuracy: 0.6299 - val_loss: 1.0617\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 45ms/step - accuracy: 0.6573 - loss: 0.9863 - val_accuracy: 0.6513 - val_loss: 1.0080\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 46ms/step - accuracy: 0.6829 - loss: 0.9241 - val_accuracy: 0.6606 - val_loss: 0.9827\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 49ms/step - accuracy: 0.7020 - loss: 0.8679 - val_accuracy: 0.6677 - val_loss: 0.9648\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7135 - loss: 0.8294 - val_accuracy: 0.6654 - val_loss: 0.9707\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.7260 - loss: 0.7902 - val_accuracy: 0.6717 - val_loss: 0.9548\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 47ms/step - accuracy: 0.7389 - loss: 0.7539 - val_accuracy: 0.6980 - val_loss: 0.8942\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.7495 - loss: 0.7203 - val_accuracy: 0.6927 - val_loss: 0.9044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b36bc628d50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        "- train_images, train_labels\n",
        "\n",
        "  From training dataset (input images and their labels).\n",
        "\n",
        "- epochs=10\n",
        "\n",
        "  The model will pass through the entire training dataset 10 times.\n",
        "\n",
        "- batch_size=64\n",
        "\n",
        "  The training data is split into mini-batches of 64 images each.\n",
        "\n",
        "  Each batch is processed before updating the model's weights.\n",
        "\n",
        "- validation_data=(test_images, test_labels)\n",
        "\n",
        "  After each epoch, the model is evaluated on the test set.\n",
        "\n",
        "  This gives insight into how well the model performs on unseen data (to monitor overfitting)."
      ],
      "metadata": {
        "id": "J1uBep4QWUMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3d: Model Evaluation\n",
        "After training, the CNN should achieve accuracy between 70–80 percent on the test data, as CIFAR-10 is a more challenging dataset."
      ],
      "metadata": {
        "id": "oFovynnYVbVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_cnn.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQMo16tfPREX",
        "outputId": "ee9ece4f-a3f8-4a1d-ca3c-e4b86d5422b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6967 - loss: 0.8983\n",
            "Test Accuracy: 0.6927000284194946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        "This runs the model on the test dataset.\n",
        "\n",
        "It returns:\n",
        "\n",
        "- loss: The model's loss value (error) on the test set, using the loss function defined during compile() — in this case, sparse categorical crossentropy.\n",
        "\n",
        "- accuracy: The percentage of correctly classified images in the test set."
      ],
      "metadata": {
        "id": "uF3BCi5TXa8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion:\n",
        "After training, the CNN achieve's accuracy of around 70 percent on the test data, as CIFAR-10 is a more challenging dataset."
      ],
      "metadata": {
        "id": "dgS4Cs4aZLwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step4: Implementing a recurrent neural network"
      ],
      "metadata": {
        "id": "xvI0katYReVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We built an RNN to predict the next value in a sine wave sequence, a classic example of time-series prediction."
      ],
      "metadata": {
        "id": "FY3qjpElRkUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4a: Create the data\n",
        "A synthetic **sine wave dataset** was created and split into sequences for training and testing."
      ],
      "metadata": {
        "id": "u32BYLCQRtl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate synthetic sine wave data\n",
        "t = np.linspace(0, 100, 10000)\n",
        "X = np.sin(t).reshape(-1, 1)\n",
        "\n",
        "# Prepare sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X_seq.append(data[i:i+seq_length])\n",
        "        y_seq.append(data[i+seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "seq_length = 100\n",
        "X_seq, y_seq = create_sequences(X, seq_length)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gDDkdpHnR1T8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        "- Generate Synthetic Sine Wave Data\n",
        "  - np.linspace(0, 100, 10000)\n",
        "\n",
        "    Generates 10,000 evenly spaced time steps from 0 to 100.\n",
        "\n",
        "    Think of this as our \"time axis\".\n",
        "\n",
        "  - np.sin(t)\n",
        "\n",
        "    Calculates the sine of each time value in t, creating a smooth wave.\n",
        "\n",
        "  - .reshape(-1, 1)\n",
        "\n",
        "    Converts the 1D array into a 2D column vector so it can be fed into a neural network later.\n",
        "\n",
        "- Create Sequences for RNN Input:\n",
        "  \n",
        "  Turns the sine wave into sliding windows (sequences) of length seq_length (e.g., 100).\n",
        "\n",
        "  For each sequence:\n",
        "\n",
        "  X_seq = the first seq_length values (input)\n",
        "\n",
        "  y_seq = the next value (target/prediction)\n",
        "\n",
        "\n",
        "    Example:\n",
        "    If data = [0.1, 0.2, 0.3, ..., 0.101] and seq_length = 3\n",
        "    Then:\n",
        "    Input X_seq[0] = [0.1, 0.2, 0.3]\n",
        "    Target y_seq[0] = 0.4 (next value after the sequence)\n",
        "\n",
        "  So, its creating sequences of 100 time steps, and the model will predict the 101st value.\n",
        "\n",
        " - Train-Test Split:\n",
        "   \n",
        "   Splits the sequence data into:\n",
        "\n",
        "    80% training\n",
        "\n",
        "    20% testing\n",
        "\n",
        "    random_state=42 ensures reproducibility of the split."
      ],
      "metadata": {
        "id": "y4w84tdEbJb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, in summary, We created a long sine wave and chopped it into many overlapping sequences of 100 time steps.\n",
        "\n",
        "Each sequence is used to predict the next value in the time series.\n",
        "\n",
        "This prepares our data for training an RNN or LSTM model, which is well-suited for sequence data."
      ],
      "metadata": {
        "id": "lPiICD4FfhAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4b: Build the RNN\n",
        "A simple RNN architecture was implemented with one recurrent layer and a single output neuron for predicting the next value in the sequence."
      ],
      "metadata": {
        "id": "8sFXt1vbTPp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RNN model\n",
        "model_rnn = models.Sequential([\n",
        "    layers.SimpleRNN(128, input_shape=(seq_length, 1)),\n",
        "    layers.Dense(1)  # Single output for next value prediction\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GmUw_7FRphu",
        "outputId": "39c5c9b9-16ce-47f3-ccbe-017ba3937598"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "It takes in a sequence of 100 sine wave values (as input) and predicts the next value in the sequence (as output).\n",
        "\n",
        "- models.Sequential([...]) :\n",
        "  Creates a Sequential model, meaning layers are stacked one after another in a linear fashion.\n",
        "\n",
        "- layers.SimpleRNN(128, input_shape=(seq_length, 1)) :\n",
        "  This is a Simple RNN layer with 128 units (neurons).\n",
        "\n",
        "- input_shape=(seq_length, 1) means:\n",
        "\n",
        "  - seq_length = 100 → the number of time steps per input sequence\n",
        "\n",
        "  - 1 → each time step has a single value (sine wave point)\n",
        "\n",
        "  This layer processes the entire sequence and outputs a single vector representing the temporal features it learned.\n",
        "\n",
        "- layers.Dense(1) :\n",
        "  A fully connected output layer with 1 neuron.\n",
        "\n",
        "  Outputs a single numeric value — the predicted next value in the sine wave sequence.\n",
        "\n",
        "    \n",
        "    Example Flow:\n",
        "    1. Input shape: (batch_size, 100, 1) — 100 time steps per sequence\n",
        "    2. RNN learns temporal patterns (like wave cycles)\n",
        "    3. Dense layer outputs 1 value — the next predicted point"
      ],
      "metadata": {
        "id": "vRg6qTVplpGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4c: Compile and train the model\n",
        "The model was compiled using the mean squared error (MSE) loss function and trained for ten epochs."
      ],
      "metadata": {
        "id": "tKuKTxOvTX1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_rnn.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "vaCwnA9lTU0e"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        "- optimizer='adam' :\n",
        "  Uses the Adam optimizer, one of the most popular and effective optimizers in deep learning.It automatically adjusts learning rates during training.Combines benefits of momentum and RMSProp.\n",
        "  \n",
        "  Works well for nonlinear data like sine waves and converges faster than basic optimizers like SGD.\n",
        "\n",
        "- loss='mse' (Mean Squared Error):\n",
        "\n",
        "  This is the loss function, which measures how far the model’s predictions are from the true values.\n",
        "\n",
        "  Lower MSE = better accuracy.\n",
        "\n",
        "  MSE is commonly used for regression tasks — like predicting the next numeric value in a sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "P4clP-7yfv8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "model_rnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL6CrfZLfyLI",
        "outputId": "ec78a0ae-9e03-4fbe-ace7-0352f1a0e6fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.0239 - val_loss: 2.3342e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 1.6284e-05 - val_loss: 3.5334e-06\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 4.6336e-06 - val_loss: 5.9749e-06\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 8.9488e-06 - val_loss: 2.3022e-06\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 3.4459e-06 - val_loss: 2.7542e-06\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 6.5751e-06 - val_loss: 3.4764e-06\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 3.6632e-06 - val_loss: 7.3360e-06\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 6.2620e-06 - val_loss: 1.0241e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 1.0845e-05 - val_loss: 1.5574e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 8.5176e-06 - val_loss: 2.8975e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b36b5ebc750>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        "- model_rnn.fit(...) :\n",
        "  This is the training function for our neural network.\n",
        "\n",
        "  It fits the model to the training data (X_train, y_train).\n",
        "\n",
        "  - epochs=10 :\n",
        "    The model will go through the entire training dataset 10 times.\n",
        "  - batch_size=32 :\n",
        "    The data is processed in mini-batches of 32 sequences at a time (helps improve training speed and stability).\n",
        "  - validation_data=(X_test, y_test) :\n",
        "    After each epoch, the model is evaluated on the test set to monitor how well it performs on unseen data."
      ],
      "metadata": {
        "id": "2IVvMm62Trfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, to summarize, We are training our RNN model over 10 cycles (epochs), in small chunks (batches of 32), while checking performance on test data after each round — a standard and efficient training approach in deep learning."
      ],
      "metadata": {
        "id": "8wfmCqGirDX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4d: Model Evaluation"
      ],
      "metadata": {
        "id": "0WvkJdmDT0ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = model_rnn.evaluate(X_test, y_test)\n",
        "print(f'Test MSE: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RSr1MKlTqY5",
        "outputId": "45ceb35b-3619-4442-c109-9453e2623eec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.9444e-05\n",
            "Test MSE: 2.8974569431738928e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What this does?\n",
        "\n",
        "This runs the model on the test data (X_test) and compares the predicted values with the actual values (y_test).\n",
        "\n",
        "Since the model was compiled with loss='mse' (mean squared error), this function returns the MSE on the test set.\n",
        "\n",
        "It's a measure of how far off the model’s predictions are, on average.\n"
      ],
      "metadata": {
        "id": "7qROz7OIrmU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion:\n",
        "\n",
        "The MSE value is 2.89 which means the average squared difference between predicted and actual values is 2.89 (which is very small—indicating good performance)."
      ],
      "metadata": {
        "id": "L1nYqmYrr5BL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summary of Results:**\n",
        "\n",
        "\n",
        "**FNN:** We achieved more than 90 percent accuracy on the Iris dataset, showcasing that FNNs are well-suited for simple classification tasks.\n",
        "\n",
        "**CNN:** We achieved around 70 percent accuracy on the CIFAR-10 dataset, highlighting the CNN’s ability to recognize spatial features in image data.\n",
        "\n",
        "**RNN:** We have minimized MSE for predicting the Sine Wave, demonstrating the RNN's capacity for handling sequential data."
      ],
      "metadata": {
        "id": "a0--IkoWvwaw"
      }
    }
  ]
}